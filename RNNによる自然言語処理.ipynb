{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 自然言語処理 入門\n",
    "# RNNによる自然言語処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "RNN(Recurrent Neural Network)は、ニューラルネットワークで__順番を持つデータ__を学習させるために提案されました。\n",
    "\n",
    "順番を持つデータというのは、時系列データや、文章、音声などのデータのことです。\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-1.png)\n",
    "\n",
    "RNNは順序を持つデータに対するネットワークです。__入力は時刻t=1からt=Tまでのデータ__（$x_1, x_2, …, x_T$）であり、__出力は各時刻tに対する出力__$y_t（y_1, y_2, …, y_T）$です。入力$x_i$は__時刻tに沿って順番に入力されます__。\n",
    "\n",
    "ネットワークは図で表すと以下のようになっています。\n",
    "\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-4.png)\n",
    "\n",
    "ここで注目したいのは、__重みであるU・V・Wは全てにおいてパラメータを共有している__という事。__ユニット数・層の構成もすべて同じ__です。そして、__隠れ層hの出力が2つに分かれていて、一つは出力層oに向かうもの、もう一つは隠れ層h自身に向かうもの__です。\n",
    "\n",
    "隠れ層自身への入力があるということは、__その時刻より前のデータも考慮に入れて予測をする__ということです。\n",
    "\n",
    "さらに、入力層からの入力は時刻tに沿って順番に与えられるため、上記のネットワークは一つの図で表すことができます（下左図）。\n",
    "\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-5.png)\n",
    "\n",
    "このように、RNNは__隠れ層が再帰的にループしているのでその時刻より前のデータも考慮に入れて予測をすることができる__という特徴があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 順伝播\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi$は一般的に$sigmoid$関数が使われます。\n",
    "\n",
    "出力層の$O_t = \\Phi_o (V h_t + b_0)$は、いつも通りの__入力に重みを掛けてバイアス項を足す__という処理を行っています。\n",
    "\n",
    "隠れ層の$h_t = \\Phi_h(U x_t + W h_{t-1} + b_h)$では、xの入力だけでは無く、t-1の隠れ層からの入力もあるので、このような式になっています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 逆伝播｜Back Propagation Through Time 法　（正直きちんと理解してない）\n",
    "RNNの逆伝播は、__過去の時間も考慮した修正__を行います。そのアルゴリズムをBack Propagation Through Time法と呼びます。\n",
    "\n",
    "### アルゴリズム\n",
    "1~4を、収束規則に応じて繰り返します。\n",
    "\n",
    "1. 順伝播\n",
    "2. 正解と出力の差から、誤差eを計算\n",
    "3. 全時刻における、各層の誤差の総和を計算する\n",
    "4. 重みを更新する\n",
    "\n",
    "### 誤差の計算\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力層の誤差$e_o$は、予測$o(t)$と正解$d(t)$の差を取ります。\n",
    "\n",
    "隠れ層の誤差は、そのユニットの前の誤差が重み付きで逆向きに流れていきます。\n",
    "\n",
    "関数dは、隠れ層を計算するために使用したsigmoid関数の微分をかけることを意味しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重みの更新\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列の勾配は、その行列の__出力側の誤差__と__行列への入力__の直積になります。\n",
    "\n",
    "U, Wに関しては、過去の分(t-1以前)も足し合わせています。上記の更新を、収束基準に達するまで繰り返します。\n",
    "\n",
    "以上がBPTT法の説明です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## RNNの応用例｜Recurrent Neural Network Language Model\n",
    "\n",
    "RNNの代表的な応用例として、RNN言語モデル(RNNLM)の構築が挙げられます。\n",
    "\n",
    "言語モデルとは、文sが現れる確率P(s)を与える確率モデルです。\n",
    "\n",
    "![](https://s3.amazonaws.com/ai-standard/nlp-3-10.png)\n",
    "\n",
    "このように、__ある単語の列が与えられたときに、次にくる単語を予測する__モデルを言語モデルと呼びます。\n",
    "\n",
    "このモデルをRNNを使って作成するのが、RNNLMと呼ばれるものです。\n",
    "\n",
    "### 言語モデルで何ができるのか？？\n",
    "言語モデルは、文の生成や、翻訳、要約、最終的に文を出力する物などの幅広い分野に利用することができます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
